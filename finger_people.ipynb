{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finger People experimental playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import urllib\n",
    "import time\n",
    "from enum import Enum\n",
    "import subprocess\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import imshow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Sources\n",
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cap(source, source_type='video'):\n",
    "    \n",
    "    if type(source) == int:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        w = 180\n",
    "        h = w * 3/4\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, w) \n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h) \n",
    "        #cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "        \n",
    "    elif source_type == 'video':\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        #cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "    else:\n",
    "        cap = WebCapture(source)\n",
    "        \n",
    "    return cap\n",
    "\n",
    "def kill_cap(cap):\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_source = 'samples/all_moves_1_180.mp4'\n",
    "cap_type = 'video'\n",
    "\n",
    "# all_moves_1 sizes: 360, 180, 90, 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_source = 0\n",
    "cap_type = 'camera'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Android (IP Webcam, moderate lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap_source = 'http://192.168.43.1:8080/shot.jpg' # IP Webcam\n",
    "cap_source = 'http://192.168.0.20:4747/mjpegfeed?320x240' # DroidCam\n",
    "cap_type = 'web'\n",
    "\n",
    "class WebCapture:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        \n",
    "    def read(self):\n",
    "        try:\n",
    "            img_resp = urllib.request.urlopen(self.url)\n",
    "            img_np = np.array(bytearray(img_resp.read()), dtype=np.uint8)\n",
    "            img = cv2.imdecode(img_np, -1)\n",
    "            return True, img\n",
    "        except:\n",
    "            return False, None\n",
    "        \n",
    "    def isOpened(self):\n",
    "        return True\n",
    "    \n",
    "    def release(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Android (DroidCam, minimal lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_source = 'http://nwam:barreltrain@192.168.0.20:4747/mjpegfeed?320x240'\n",
    "cap_type = 'video'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helpers\n",
    "### Hand Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cap_source = 'http://192.168.43.1:8080/shot.jpg' # IP Webcam\n",
    "cap_source = 'http://192.168.0.20:4747/mjpegfeed?320x240' # DroidCam\n",
    "cap_type = 'web'\n",
    "\n",
    "class WebCapture:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        \n",
    "    def read(self):\n",
    "        try:\n",
    "            img_resp = urllib.request.urlopen(self.url)\n",
    "            img_np = np.array(bytearray(img_resp.read()), dtype=np.uint8)\n",
    "            img = cv2.imdecode(img_np, -1)\n",
    "            return True, img\n",
    "        except:\n",
    "            return False, None\n",
    "        \n",
    "    def isOpened(self):\n",
    "        return True\n",
    "    \n",
    "    def release(self):\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_mask(img, lower, upper):\n",
    "    '''\n",
    "    Given a BGR image, returns a mask of pixels within lower and upper HSV space\n",
    "    \n",
    "    mask = hsv_mask(img, lower, upper)\n",
    "    \n",
    "    input\n",
    "        img: A BGR image\n",
    "        lower: 3-tuple with hue, saturation, and value of lower cutoff of mask\n",
    "        upper: 3-tuple with hue, saturation, and value of upper cutoff of mask\n",
    "        \n",
    "    output\n",
    "        mask: binary mask of pixels with HSV values between lower and upper\n",
    "    '''\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros((img.shape[:2]), dtype=np.uint8)\n",
    "    \n",
    "    if lower[0] > upper[0]:\n",
    "        # To account for hue wrapping around 180 to 0\n",
    "        lower_middle = (180, upper[1], upper[2])\n",
    "        upper_middle = (0,   lower[1], lower[2])\n",
    "        \n",
    "        mask_lower = cv2.inRange(hsv, lower, lower_middle)\n",
    "        mask_upper = cv2.inRange(hsv, upper_middle, upper)\n",
    "        \n",
    "        mask = mask_lower + mask_upper\n",
    "        \n",
    "    else:\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_roi_sample(cap, size=1/8):\n",
    "    '''\n",
    "    Draws a rectangle on the screen\n",
    "    Returns the pixels in the region upon pressing space\n",
    "    \n",
    "    size is a fraction of the screen height\n",
    "    '''\n",
    "    _ret, frame = cap.read()\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "    \n",
    "    size /= 2\n",
    "    p0 = (int(w/2-h*size), int(h/2-h*size))\n",
    "    p1 = (int(w/2+h*size), int(h/2+h*size))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        _ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)  \n",
    "        \n",
    "        #frame = cv2.GaussianBlur(frame, (13,13), 0)\n",
    "        \n",
    "        if not _ret:\n",
    "            break\n",
    "            \n",
    "        frame_display = frame.copy()\n",
    "        cv2.rectangle(frame_display, p0, p1, (0,255,0), 2)\n",
    "        cv2.imshow('frame', frame_display)\n",
    "        \n",
    "        key = cv2.waitKey(5)\n",
    "        if key == ord(' '):\n",
    "            break\n",
    "            \n",
    "    box_sample = frame[p0[1]:p1[1], p0[0]:p1[0]]\n",
    "    return box_sample\n",
    "\n",
    "def get_hsv_range(imgs):\n",
    "    '''\n",
    "    min_hsv, max_hsv = get_hsv_range(imgs)\n",
    "    \n",
    "    Finds and returns the bounds of a set of hsv images.\n",
    "    Shifts hue such that blue is around the 180/0 border \n",
    "    so that skin range can be easily evaluated\n",
    "    \n",
    "    Input\n",
    "        imgs: bgr images\n",
    "    \n",
    "    Output\n",
    "        min_hsv: 3-tuple containing the mininum hue, saturation, and value found in img\n",
    "        max_hsv: 3-tuple containing the maximum hue, saturation, and value found in img\n",
    "    '''\n",
    "    min_hsvs = []\n",
    "    max_hsvs = []\n",
    "    \n",
    "    for img in imgs:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        hue = img[:,:,0]\n",
    "        sat = img[:,:,1]\n",
    "        val = img[:,:,2]\n",
    "\n",
    "        hue = (hue + 90)%180 # shift skin hues away from the 180/0 border\n",
    "        min_hue, max_hue, _, _ = cv2.minMaxLoc(hue)\n",
    "        min_sat, max_sat, _, _ = cv2.minMaxLoc(sat)\n",
    "        min_val, max_val, _, _ = cv2.minMaxLoc(val)\n",
    "        \n",
    "        min_hsvs.append((min_hue, min_sat, min_val))\n",
    "        max_hsvs.append((max_hue, max_sat, max_val))\n",
    "        \n",
    "    # NOTE: these functions could be changed\n",
    "    #... using minimax for now\n",
    "    min_hsv = np.amin(np.array(min_hsvs), axis=0)\n",
    "    max_hsv = np.amax(np.array(max_hsvs), axis=0)\n",
    "    \n",
    "    min_hsv[0] = (min_hsv[0] + 90)%180\n",
    "    max_hsv[0] = (max_hsv[0] + 90)%180\n",
    "\n",
    "    return min_hsv, max_hsv\n",
    "\n",
    "def mean_hist(samples, channels=[0,1], ranges=[0,180,0,256], bins=[32,32]):\n",
    "    '''\n",
    "    Gets a mean histogram of all the sample images.\n",
    "    \n",
    "    Inputs:\n",
    "        samples is a list of sample images\n",
    "        channels defines the channels to use\n",
    "        ranges specifies the range of each channel\n",
    "        num_bins is the number of bins for each channel\n",
    "        \n",
    "    Outputs:\n",
    "        hist is the mean histogram\n",
    "    '''\n",
    "    hists = np.array([cv2.calcHist([sample], channels, None, bins, ranges) for sample in samples])\n",
    "    hist = np.mean(hists, axis=0)\n",
    "    return hist\n",
    "\n",
    "def hist_mask(img, hist, thresh=1, channels=[0,1], ranges=[0,180,0,256]):\n",
    "    backProj = cv2.calcBackProject([img], channels, hist, ranges, 1)\n",
    "    if thresh is not None:\n",
    "        ret, mask = cv2.threshold(backProj, 1, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        mask = backProj\n",
    "    return mask\n",
    "\n",
    "def lowest_large_blob(mask, blob_thresh):\n",
    "    ''' Return a mask of the lowest blob larger than blob_thresh '''\n",
    "    # Find the lowest contour above the min size -- this should be a hand\n",
    "    im, contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    lowest_contour = None\n",
    "    lowest_contour_height = math.inf\n",
    "    lowest_contour_area = 0\n",
    "    \n",
    "    for i, contour in enumerate(contours):\n",
    "        contour_area = cv2.contourArea(contour)\n",
    "        if contour_area <= blob_thresh:\n",
    "            continue\n",
    "            \n",
    "        m = cv2.moments(contour)\n",
    "        contour_height = m['m10']/m['m00']\n",
    "\n",
    "        if contour_height < lowest_contour_height:\n",
    "            lowest_contour = i\n",
    "            lowest_contour_height = contour_height\n",
    "            lowest_contour_area = contour_area\n",
    "            \n",
    "    # Draw in hand blob\n",
    "    mask = np.zeros_like(skin_mask)\n",
    "    if lowest_contour:\n",
    "        cv2.drawContours(mask, contours, lowest_contour, 255, -1)\n",
    "        \n",
    "    return mask\n",
    "\n",
    "def largest_blob(mask, thresh=750):\n",
    "    ''' Return a mask of the lowest blob larger than blob_thresh '''\n",
    "    im, contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if len(contours) > 0:\n",
    "        largest_contour = max(contours, key=cv2.contourArea)\n",
    "        \n",
    "        if cv2.contourArea(largest_contour) > thresh:\n",
    "            return largest_contour\n",
    "    \n",
    "    return None\n",
    "\n",
    "def contour_pos(contour):\n",
    "    m = cv2.moments(contour)\n",
    "    if m['m00'] == 0:\n",
    "        cx = None\n",
    "        cy = None\n",
    "    else:\n",
    "        cx = m['m10']/m['m00']\n",
    "        cy = m['m01']/m['m00']\n",
    "\n",
    "    return np.array((cx,cy))\n",
    "\n",
    "def contour2mask(contour, shape):\n",
    "    # Draw in hand blob\n",
    "    mask = np.zeros_like(shape)\n",
    "    if contour is not None:\n",
    "        cv2.drawContours(mask, [contour], 0, 255, -1)\n",
    "        \n",
    "    return mask\n",
    "\n",
    "\n",
    "# HSV ranges for skin detection (with perferct conditions)\n",
    "#skin_hsv_lower = np.array([0,  24,  80 ], dtype = \"uint8\")\n",
    "#skin_hsv_upper = np.array([20, 120, 255], dtype = \"uint8\")\n",
    "#skin_hsv_lower, skin_hsv_upper = get_hsv_range(skin_samples)  \n",
    "#print('Skin range {} {}'.format(skin_hsv_lower, skin_hsv_upper))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gesture(Enum):\n",
    "    IDLE = 0\n",
    "    RUN  = 1\n",
    "    JUMP = 2\n",
    "    KICK = 3\n",
    "    \n",
    "class Direction(Enum):\n",
    "    RIGHT = 'R'\n",
    "    LEFT = 'L'\n",
    "\n",
    "class Hand:\n",
    "    def __init__(self):\n",
    "        self.run = False\n",
    "        self.jump = False\n",
    "        self.kick = False\n",
    "        \n",
    "        self._leg_speed = 0.0\n",
    "        self.body_facing = Direction.LEFT\n",
    "        \n",
    "        self.r_direction = Direction.RIGHT\n",
    "        self.screen_width = 176 # unrelated to hand, but whatever\n",
    "        self.r_screen_ratio = 7/9 # how much of the screen width is forward?\n",
    "        #self.r_direction_thresh = 5.0 # px/frame\n",
    "        #self.r_direction_ratio = 1.5 # x must be ratio more than y\n",
    "        self.r_thresh = 3.5 # avg opflow\n",
    "        self.w_thresh = 1.0 # walk thresh\n",
    "        \n",
    "        self.j_thresh = 7.5 # px/frame\n",
    "        self.j_ratio  = 1.5 # y must be ratio more than x\n",
    "        self.j_reset_thresh = 4.0 #px/frame\n",
    "        self.j_start = 0\n",
    "        self.j_cooldown = 0.8 # seconds\n",
    "        self._position = np.zeros(2)\n",
    "        self._velocity = np.zeros(2)\n",
    "        self.velocity_alpha = 0.5\n",
    "        \n",
    "        self.k_start = 0\n",
    "\n",
    "    @property\n",
    "    def leg_speed(self):\n",
    "        return self._leg_speed\n",
    "        \n",
    "    @property\n",
    "    def position(self):\n",
    "        return self._position\n",
    "    \n",
    "    @property\n",
    "    def velocity(self):\n",
    "        return self._velocity\n",
    "    \n",
    "    \n",
    "    @leg_speed.setter\n",
    "    def leg_speed(self, speed):\n",
    "        self._leg_speed = speed\n",
    "        \n",
    "        if self.leg_speed > self.w_thresh:\n",
    "            self.run = True\n",
    "        else:\n",
    "            self.run = False\n",
    "        \n",
    "    @position.setter\n",
    "    def position(self, pos):\n",
    "        prev_pos = self.position\n",
    "        \n",
    "        # Set velocity\n",
    "        if None not in pos and None not in prev_pos:\n",
    "            self.velocity = self.velocity_alpha * self.velocity + (1-self.velocity_alpha) * (prev_pos - pos)\n",
    "        else:\n",
    "            self.velocity = np.zeros(2)\n",
    "            \n",
    "        # Update run direction\n",
    "        if None not in pos:\n",
    "            h_pos = pos[0] if self.body_facing is Direction.LEFT else self.screen_width - pos[0]\n",
    "            if h_pos > self.screen_width * self.r_screen_ratio:\n",
    "                self.r_direction = Direction.LEFT\n",
    "            else:\n",
    "                self.r_direction = Direction.RIGHT\n",
    "\n",
    "            self._position = np.array(pos)\n",
    "        \n",
    "    @velocity.setter\n",
    "    def velocity(self, v):\n",
    "        if v[0] is not None and v[1] is not None:\n",
    "            self._velocity = np.array(v)\n",
    "        \n",
    "        # Update jump\n",
    "        if abs(self.velocity[1]) > abs(self.velocity[0])*self.j_ratio:\n",
    "            if self.velocity[1] > self.j_thresh:\n",
    "                self.jump = True\n",
    "                self.j_start = time.time()\n",
    "\n",
    "            elif self.jump == True and self.velocity[1] < -1*self.j_reset_thresh:\n",
    "                self.jump = False          \n",
    "            \n",
    "#         # Update run direction\n",
    "#         if abs(self.velocity[0]) > abs(self.velocity[1])*self.r_direction_ratio:\n",
    "#             h_velocity = self.velocity[0]\n",
    "#             if self.body_facing is Direction.RIGHT:\n",
    "#                 h_velocity *= -1\n",
    "                \n",
    "#             if self.r_direction is Direction.LEFT and self.velocity[0] > self.r_direction_thresh:\n",
    "#                 self.r_direction = Direction.RIGHT\n",
    "#             elif self.r_direction is Direction.RIGHT and self.velocity[0] < -1*self.r_direction_thresh:\n",
    "#                 self.r_direction = Direction.LEFT\n",
    "                            \n",
    "    def check_cooldowns(self):\n",
    "        if time.time() - self.j_start > self.j_cooldown:\n",
    "            self.jump = False\n",
    "    \n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def gestures(self):\n",
    "        g = []\n",
    "        if self.run:\n",
    "            g.append(Gesture.RUN)\n",
    "        if self.jump:\n",
    "            g.append(Gesture.JUMP)\n",
    "        if self.kick:\n",
    "            g.append(Gesture.KICK)\n",
    "        return g\n",
    "    \n",
    "    def gestures_pretty(self):\n",
    "        g = ''\n",
    "        g += 'R' if self.run  else '0'\n",
    "        g += 'J' if self.jump else '0'\n",
    "        g += 'K' if self.kick else '0'\n",
    "        return g\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0. -2.]\n",
      "000\n",
      "Direction.RIGHT\n",
      "[ 9.5 -0.5]\n",
      "000\n",
      "Direction.RIGHT\n"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "hand = Hand()\n",
    "hand.j_cooldown = 5.0\n",
    "hand.position = (0, 4)\n",
    "print(hand.velocity)\n",
    "print(hand.gestures_pretty())\n",
    "print(hand.r_direction)\n",
    "hand.position = (-19, 3)\n",
    "print(hand.velocity)\n",
    "print(hand.gestures_pretty())\n",
    "print(hand.r_direction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Hand.gestures_pretty of <__main__.Hand object at 0x7f22dd2be2e8>>\n",
      "<bound method Hand.gestures_pretty of <__main__.Hand object at 0x7f22dd2be2e8>>\n"
     ]
    }
   ],
   "source": [
    "print(hand.gestures_pretty)\n",
    "hand.velocity = (4, -16)\n",
    "print(hand.gestures_pretty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Game Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GameInput:\n",
    "    KEY_A = 'f'\n",
    "    KEY_B = 'd'\n",
    "\n",
    "    KEY_L = 'Left'\n",
    "    KEY_R = 'Right'\n",
    "    KEY_U = 'Up'\n",
    "    KEY_D = 'Down'\n",
    "    \n",
    "    TAP_TIME = 1/30 # seconds\n",
    "\n",
    "    @staticmethod\n",
    "    def keydown(key):\n",
    "        subprocess.run(['xte', 'keydown {}'.format(key)]) # Linux only\n",
    "        \n",
    "    @staticmethod\n",
    "    def keyup(key):\n",
    "        subprocess.run(['xte', 'keyup {}'.format(key)]) # Linux only\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def walk(cls, direction=None):\n",
    "        if direction is Direction.LEFT:\n",
    "            cls.keydown(cls.KEY_L)\n",
    "            cls.keyup(cls.KEY_R)\n",
    "        else:\n",
    "            cls.keydown(cls.KEY_R)\n",
    "            cls.keyup(cls.KEY_L)\n",
    "            \n",
    "    @classmethod\n",
    "    def run(cls, direction=None):\n",
    "        cls.keydown(cls.KEY_B)  \n",
    "        if direction is Direction.LEFT:\n",
    "            cls.keydown(cls.KEY_L)\n",
    "        else:\n",
    "            cls.keydown(cls.KEY_R)\n",
    "            \n",
    "    @classmethod\n",
    "    def stop_move(cls):\n",
    "        cls.keyup(cls.KEY_L)\n",
    "        cls.keyup(cls.KEY_R)\n",
    "            \n",
    "    @classmethod\n",
    "    def stop_run(cls):\n",
    "        cls.keyup(cls.KEY_B)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def jump(cls):\n",
    "        cls.keydown(cls.KEY_A)\n",
    "        \n",
    "    @classmethod\n",
    "    def stop_jump(cls):\n",
    "        cls.keyup(cls.KEY_A)\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def kick(cls):\n",
    "        cls.keydown(cls.KEY_B)\n",
    "        time.sleep(TAP_TIME)\n",
    "        cls.keyup(cls.KEY_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skin Clibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQ0AAAEWCAYAAAB8A8JQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAFGxJREFUeJzt3X+wHWV9x/H35yY3CYTwIwRijNEATXVSikFvASsKIiBmrJFKrcggKhqnSgVqp0WdQsDaYkeh/rahRFJBFEUKTRk0pmRAq5ErhCSACNIgCSEhBEiI5nJ/fPvHbuBwPXtynuTsnnu4n9fMmbtnn7O73+wknzxnn7vPKiIwM2tWV7sLMLPO4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODWsrSSdKWlvQdrykeyouyXbBoTEKSLpa0jeGrTtO0hOSplVw/D+WtFTSk/mrV9JbdrVdRCyPiD8quz5L49AYHc4F3irpJABJE4ArgI9HxIZWHkjSmGHvBSwBbgYOBl4CnA8808rjWnUcGqNARDwB/DWwUNJE4CLg1xFxFWQhIumLkjZIWi/pMknj8rYPSlq+c1+SxkoKSTPz91dL+oqkWyRtB94w7PBTgZcDV0REf0T0RcTtEfGTerVKOl/SGkkvHf7VRdI6SX8jabWkpyVdK2l8S06SNc2hMUpExHeBO4Frgfn5a6cLgR7gCOBI4PXAJxJ2/x7gYmAS8NNhbZuAh4BrJM2TdHDRTiRdApwBHBcRjxZ87F3AScChwGuBMxPqtBZwaIwuHwFOAC6JiEdq1p8BLIiIxyNiE3AJaf8Yb4iIn0bEUET01TZExBBwPLAeuBzYIOlWSYfVfEySvgAcB5yQ94yK/GtEPJZ/ZgkwJ6FOawGHxigSERuBzcDwEYmXAg/XvH8YmJ6w60caNUbEIxHxkYg4FDgE6AeuqvnIgcAHgc9ExNZdHOuxmuXfAvsk1Gkt4NAwgEeBV9S8fzlZzwBgO7B3TdtL6mzf9K3SEfEb4KvA4TWrNwNvB66WdEyz+7L2cGgYZNc5LpQ0RdJBwD8AV+dtdwNH5MOme5FdRG1avs+LJB2qzEHA+4Gf1X4uIpYB7wVulNSzp38gK49DwyC7iHk3sAZYBawA/hkgIu4F/glYDtwP3Ja47z7gMOBWsmHW1fnPDwz/YETcAnwIWCLJ1ypGKHkSHjNL4Z6GmSVxaJhZEoeGmSVxaJhZkrHtLqAZ4zQ+JjCx3WWYvWjtYDvPRp+a+WxbQkPSKcAXgDHAv0fEpY0+P4GJHD3m5PqNQ4Mtr89stFkRy5r+bOVfT/Jbp78CvBWYDZwuaXbVdZjZ7mnHNY2jgAcj4qGIeBb4NjCvDXWY2W5oR2hM54U3OK2jzs1RkubnMzz19tM3vNnM2mTEjp5ExMKI6ImInm48z4rZSNGO0FgPzKh5/zKev6PSzEa4doye3AHMknQIWVi8m2zmp8ZejKMkKh7h0tjuwrau/SYVtj17+CsK2x47ZkLxdvvWvwepe1txjf0F2wB87rTFhW1vn/jbwra598+tu/6X98youx6g++ni//tm/Kj4q+24e9cVtg099XTd9dE/ULjNi/LvaB2Vh0ZEDEg6B/gB2ZDroojwNPVmHaItv6cRETeTzU5tZh1mxF4INbORyaFhZkkcGmaWxKFhZkk6Yrq/fTU5ju46sW6bxo0r3C76RsZvko6ZWvB8oEnFd+7uOPTAwra+/cYUtvXvXfz/wH5rdxS2jfvNlsK2IkMbNhY3dhcPGQ890+CJjCqoP4aarKpFiv5dNBgmL9ymA6yIZWyNLU3d5eqehpklcWiYWRKHhpklcWiYWRKHhpkl6Yg5QpEKb+Dq2qv4Jqyi6+0NbzpqYMysQwrb+l9SfBNZ//j6ox1d/cUjAmP6im9+2v+OTYVtAw83eBZzg6v7u3dGGthRPFLTUIzwm746eISkVdzTMLMkDg0zS+LQMLMkDg0zS+LQMLMkDg0zS9IZQ64RRP+zdZuGDptVuFnX0/XnolRff+E224+YVtjW6GawSQ8W34TV/ZsNddcPPll/Hkqg4XyTLR8eNUvgnoaZJXFomFkSh4aZJXFomFkSh4aZJXFomFmSzhhyFWhs/VLHPPpE4Waxvf6Qa3QX/7H3/t8Hi/fXYM7RoR3FbYOj5HF9Njq0JTQkrQW2AYPAQET0tKMOM0vXzp7GmyJicxuPb2a7wdc0zCxJu0IjgB9K+oWk+fU+IGm+pF5Jvf0xMp5fYmbt+3pybESsl3QwsFTSLyPittoPRMRCYCHAvl2TPcea2QjRlp5GRKzPf24CbgCOakcdZpau8p6GpIlAV0Rsy5dPBi5puFFADNS/t3Nwy5OFm3WNH193/dDTW4sPVXAcM8u04+vJVOAGZc/EHAt8KyJuaUMdZrYbKg+NiHgIeHXVxzWz1vCQq5klcWiYWRKHhpklcWiYWZLOuMsVIBtt+X2DxXeQDm4tHlo1s93jnoaZJXFomFkSh4aZJXFomFkSh4aZJemM0RMJjRtXt6nRvJ1m1nruaZhZEoeGmSVxaJhZEoeGmSVxaJhZEoeGmSXpjCHXCKLfc3eajQTuaZhZEoeGmSVxaJhZEoeGmSVxaJhZEoeGmSXpiCFXdXXRtdeEum1D27dXXI3Z6FZaT0PSIkmbJK2pWTdZ0lJJD+Q/Dyjr+GZWjjK/nlwFnDJs3QXAsoiYBSzL35tZByktNCLiNmDLsNXzgMX58mLgHWUd38zKUfU1jakRsSFffozsCfJ1SZoPzAeYoIkVlGZmzWjb6ElEBBAN2hdGRE9E9IxT/YugZla9qkNjo6RpAPnPTRUf38z2UNWhcRNwVr58FnBjMxvF0BBD27fXfZlZtcoccr0W+CnwSknrJJ0NXAqcJOkB4MT8vZl1kNIuhEbE6QVNby7rmGZWPv8auZklcWiYWRKHhpklcWiYWZKOuMsVgK4x9dcPDVZbh9ko556GmSVxaJhZEoeGmSVxaJhZEoeGmSVxaJhZks4ZcvXQqtmI4J6GmSVxaJhZEoeGmSVxaJhZEoeGmSXpnNETqf76KJzQ3MxK4J6GmSVxaJhZEoeGmSVxaJhZEoeGmSVxaJhZkqaHXCUdC8yKiG9IOgjYJyL+r7zSmqyre1xhW/Q/W2ElZqNDUz0NSRcBfw98Il/VDVy9i20WSdokaU3NugWS1ktamb/m7m7hZtYezX49ORV4O7AdICIeBSbtYpurgFPqrL88Iubkr5ubLdTMRoZmQ+PZiAggACRN3NUGEXEbsGUPajOzEajZ0LhO0r8B+0v6EPAj4IrdPOY5klblX18OKPqQpPmSeiX19tO3m4cys1ZTNHnvhqSTgJMBAT+IiKVNbDMTWBIRh+fvpwKbyXosnwamRcQHdrWffTU5ju46sf4xxnYXbucLoWbNWRHL2BpbCm7weqGmR0/ykNhlUOxiHxt3Lku6AliyJ/szs+o1FRqStpFfzwDGkY2ebI+IfVMOJmlaRGzI354KrGn0+ee2GzuWMVMOqts2+PgTKSWY2R5qKjQi4rmREkkC5gHHNNpG0rXA8cAUSeuAi4DjJc0hC6C1wId3q2oza5umr2n83obSXRFxZIvrqWu/7oPjdVP+om5bw56GZzA3a0rLr2lI+vOat11AD7BjN2ozsw7X7IXQP6tZHiD7ajGv5dWY2YjX7DWN95ddiJl1hoahIelLPD9q8nsi4mMtr8jMRrRd9TR6a5YvJhsBqVwMDDC46fGCRk8sbFalhqEREYt3Lks6r/a9mY1OKZPw+L90M/PMXWaWZlcXQmt/fXxvSVt3NgGR+mvkZtb5dnVNY1cT7ZjZKOOvJ2aWpHOe5eqhVbMRwT0NM0vi0DCzJA4NM0vi0DCzJA4NM0vSGaMnyuYJrScGBiouxmx0c0/DzJI4NMwsiUPDzJI4NMwsiUPDzJI4NMwsSWmhIWmGpFsl3SvpHknn5usnS1oq6YH8Z+GT458T2dBqvZeZVavMnsYA8PGImE32CMePSpoNXAAsi4hZwLL8vZl1iNJCIyI2RMSd+fI24D5gOtlDlnZOULwYeEdZNZhZ61VyTUPSTOBIYAUwtebJ8Y8BU6uowcxao/TQkLQPcD1wXkRsrW2L7OnTdWfXkTRfUq+k3n76yi7TzJpUamhI6iYLjGsi4vv56o2SpuXt04BN9baNiIUR0RMRPd2ML7NMM0tQ5uiJgCuB+yLispqmm4Cz8uWzgBvLqsHMWq/Mu1xfD5wJrJa0Ml/3SeBS4DpJZwMPA+8qsQYza7HSQiMifkz2fJR63lzWcc2sXP6NUDNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyQODTNL4tAwsyRlzhHaWiqYOTDqPgHBzErinoaZJXFomFkSh4aZJXFomFkSh4aZJXFomFmSMp/lOkPSrZLulXSPpHPz9QskrZe0Mn/NbWqHEfVfZlapMn9PYwD4eETcKWkS8AtJS/O2yyPicyUe28xKUuazXDcAG/LlbZLuA6aXdTwzq0Yl1zQkzQSOBFbkq86RtErSIkkHVFGDmbVG6aEhaR/geuC8iNgKfA04DJhD1hP5fMF28yX1Surtp6/sMs2sSaWGhqRussC4JiK+DxARGyNiMCKGgCuAo+ptGxELI6InInq6GV9mmWaWoMzREwFXAvdFxGU166fVfOxUYE1ZNZhZ65U5evJ64ExgtaSV+bpPAqdLmgMEsBb4cFN76xpTf30MFW/jIVmzlitz9OTHQL372W8u65hmVj7/RqiZJXFomFkSh4aZJXFomFkSh4aZJemciYWHBttdgZnhnoaZJXJomFkSh4aZJXFomFkSh4aZJXFomFmSzhly9bNczUYE9zTMLIlDw8ySODTMLIlDw8ySODTMLIlDw8ySdM6Qq4dWzUYE9zTMLIlDw8ySODTMLIlDw8ySODTMLEmZz3KdIOnnku6WdI+ki/P1h0haIelBSd+RNK6sGsys9crsafQBJ0TEq4E5wCmSjgE+C1weEX8APAmcXWINZtZipYVGZJ7J33bnrwBOAL6Xr18MvKOsGsys9Uq9piFpTP7E+E3AUuDXwFMRMZB/ZB0wvcwazKy1Sg2NiBiMiDnAy4CjgFc1u62k+ZJ6JfX201dajWaWppLRk4h4CrgVeB2wv6Sdv77+MmB9wTYLI6InInq6GV9FmWbWhDJHTw6StH++vBdwEnAfWXicln/sLODGsmows9Yr84a1acBiSWPIwum6iFgi6V7g25L+EbgLuLLEGsysxUoLjYhYBRxZZ/1DZNc3zKwD+TdCzSyJQ8PMkjg0zCyJQ8PMkjg0zCyJogPm3pT0OPBw/nYKsLmN5ezkOl7IdbxQp9Xxiog4qJkddkRo1JLUGxE9rsN1uI721OGvJ2aWxKFhZkk6MTQWtruAnOt4IdfxQi/aOjrumoaZtVcn9jTMrI0cGmaWpKNCQ9Ipku7PZzK/oI11rJW0WtJKSb0VHneRpE2S1tSsmyxpqaQH8p8HtKmOBZLW5+dkpaS5FdQxQ9Ktku7NZ7w/N19f6TlpUEel56SyJwBEREe8gDFkc4weCowD7gZmt6mWtcCUNhz3jcBrgDU16/4FuCBfvgD4bJvqWAD8bcXnYxrwmnx5EvArYHbV56RBHZWeE0DAPvlyN7ACOAa4Dnh3vv7rwF/tyXE6qadxFPBgRDwUEc8C3wbmtbmmSkXEbcCWYavnkc3qDhXN7l5QR+UiYkNE3JkvbyObGW46FZ+TBnVUKjKlPwGgk0JjOvBIzft2zmQewA8l/ULS/DbVsNPUiNiQLz8GTG1jLedIWpV/fSn9a1ItSTPJJn1aQRvPybA6oOJzUsUTADopNEaSYyPiNcBbgY9KemO7C4LsfxqyQGuHrwGHkT0YawPw+aoOLGkf4HrgvIjYWttW5TmpU0fl5yT24AkAzeqk0FgPzKh5XziTedkiYn3+cxNwA+2dvnCjpGkA+c9N7SgiIjbmf2GHgCuo6JxI6ib7h3pNRHw/X135OalXR7vOSX7s5CcANKuTQuMOYFZ+JXgc8G7gpqqLkDRR0qSdy8DJwJrGW5XqJrJZ3aGNs7vv/EeaO5UKzokkkU1MfV9EXFbTVOk5Kaqj6nNS2RMAqrqy26Krw3PJrkz/GvhUm2o4lGzk5m7gnirrAK4l6+b2k303PRs4EFgGPAD8CJjcpjq+CawGVpH9o51WQR3Hkn31WAWszF9zqz4nDeqo9JwAR5DN8L+KLKAurPk7+3PgQeC7wPg9OY5/jdzMknTS1xMzGwEcGmaWxKFhZkkcGmaWxKFhZkkcGqOQpE/ld0Guyu++PLrBZ98n6aUtPPZMSe+ped8j6Yut2r+Vr8ynxtsIJOl1wNvI7srskzSF7K7hIu8jG/N/NOEYY+P5ex2Gmwm8B/gWQET0ApVNL2B7zj2N0WcasDki+gAiYnNEPCrpQkl3SFojaaEypwE9wDV5j2SvfC6RKfBcL2F5vrxA0jcl/QT4Zt6juF3SnfnrT/PjXwq8Id/f+ZKOl7Qk38dkSf+Z94B+JumImn0vkrRc0kOSPlbpGbMXcGiMPj8EZkj6laSvSjouX//liPiTiDgc2At4W0R8j6wXcEZEzImI3+1i37OBEyPidLL7PU6K7Ma+vwR2fgW5ALg939/lw7a/GLgrIo4APgn8R03bq4C3kN2/cVF+r4e1gb+ejDIR8Yyk1wJvAN4EfEfZLGjbJP0dsDcwmexX5P8rcfc31QRLN/BlSXOAQeAPm9j+WOCdeZ3/I+lASfvmbf+d9476JG0iu919XWJ91gIOjVEoIgaB5cBySauBD5Pdt9ATEY9IWgBMKNh8gOd7qMM/s71m+XxgI/Dq/PM79rDsvprlQfx3t2389WSUkfRKSbNqVs0B7s+XN+dzQpxW076NbAq7ndYCr82X39ngUPsBGyK7LfxMsuka6+2v1u3AGXmdx5Nde9la8FlrE6f16LMP8KX8FuoBsjsf5wNPkY2SPEY2DcFOVwFfl/Q7srkZLgaulPRpst5Kka8C10t6L3ALz/dCVgGDku7O931XzTYLgEWSVgG/5fnb220E8V2uZpbEX0/MLIlDw8ySODTMLIlDw8ySODTMLIlDw8ySODTMLMn/A3ANNTLt9nuiAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa88d944748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HUE = 0\n",
    "SAT = 1\n",
    "VAL = 2\n",
    "channels = [HUE, SAT]\n",
    "\n",
    "HUE_RANGE = (0,180)\n",
    "SAT_RANGE = (0,256)\n",
    "VAL_RANGE = (0, 256)\n",
    "ranges = [*HUE_RANGE, *SAT_RANGE]\n",
    "\n",
    "num_bins = 32\n",
    "bins = [num_bins]*len(channels)\n",
    "\n",
    "sat_thresh = 16 # any saturations below will be thrown out due to instability\n",
    "sat_thresh_bin = int(sat_thresh/SAT_RANGE[1]*num_bins)\n",
    "\n",
    "# Get samples of skin\n",
    "cap = get_cap(cap_source, cap_type)\n",
    "skin_samples = []\n",
    "for _ in range(5):\n",
    "    skin_samples.append(cv2.cvtColor(get_roi_sample(cap), cv2.COLOR_BGR2HSV))\n",
    "kill_cap(cap)\n",
    "\n",
    "# Calculate histogram\n",
    "skin_hist = mean_hist(skin_samples, channels=channels, ranges=ranges, bins=bins)\n",
    "#skin_hist[:, :sat_thresh_bin] = 0\n",
    "plt.xlabel('Saturation')\n",
    "plt.ylabel('Hue')\n",
    "plt.title('Your Skin')\n",
    "plt.imshow(skin_hist)\n",
    "\n",
    "# Create function to mask skin\n",
    "mask_skin = lambda frame, thresh=1: hist_mask(frame, skin_hist, thresh=thresh, channels=channels, ranges=ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finger People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = get_cap(cap_source, cap_type)\n",
    "\n",
    "hand = Hand()\n",
    "\n",
    "walks_left = True # The direction the finger person is facing in the (mirrored) frame\n",
    "if not walks_left:\n",
    "    hand.body_facing = Direction.RIGHT\n",
    "    \n",
    "input_toggle = False\n",
    "\n",
    "min_blob_size = 0\n",
    "mhi_alpha = 0.5\n",
    "\n",
    "# Parameters for farneback optical flow\n",
    "fb_params = dict( pyr_scale = 0.5, \n",
    "                  levels = 3, \n",
    "                  winsize = 5, \n",
    "                  iterations = 3, \n",
    "                  poly_n = 5,\n",
    "                  poly_sigma = 1.2, \n",
    "                  flags = 0 )\n",
    "\n",
    "# Take the first frame\n",
    "_ret, init_frame = cap.read()\n",
    "prvs = cv2.cvtColor(init_frame,cv2.COLOR_BGR2GRAY)\n",
    "frame1 = cv2.flip(init_frame, 1)\n",
    "\n",
    "h = init_frame.shape[0]\n",
    "w = init_frame.shape[1]\n",
    "hand.screen_width = w\n",
    "\n",
    "# For color representation of optical flow\n",
    "flow_vis = np.zeros_like(init_frame)\n",
    "flow_vis[...,1] = 255\n",
    "\n",
    "# Motion history image\n",
    "mag_hist = np.zeros((init_frame.shape[:2]), dtype=np.float32)\n",
    "ang_hist = np.zeros((init_frame.shape[:2]), dtype=np.float32)\n",
    "mhi = np.zeros_like(init_frame)\n",
    "mhi[...,1] = 255\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Get the next frame\n",
    "    _ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)  \n",
    "    if not _ret:\n",
    "        break\n",
    "    debug = frame.copy()\n",
    "      \n",
    "    \n",
    "    \n",
    "    ''' SKIN MASK '''\n",
    "    blurred = cv2.GaussianBlur(frame, (7,7), 0)\n",
    "    skin_mask = mask_skin(cv2.cvtColor(blurred, cv2.COLOR_BGR2HSV), thresh=25)\n",
    "    \n",
    "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "    hand_mask = skin_mask\n",
    "    \n",
    "    hand_mask = cv2.morphologyEx(hand_mask, cv2.MORPH_OPEN, kernel, iterations = 1)\n",
    "    hand_mask = cv2.morphologyEx(hand_mask, cv2.MORPH_CLOSE, kernel, iterations = 2)\n",
    "    hand_contour = largest_blob(hand_mask, thresh=min_blob_size)\n",
    "    hand_mask = contour2mask(hand_contour, shape=skin_mask)\n",
    "    \n",
    "    hand.position = contour_pos(hand_contour)\n",
    "    \n",
    "    # debug\n",
    "    if hand.position[0] is not None:\n",
    "        cv2.putText(debug, '{:.2f},{:.2f}'.format(hand.velocity[0], hand.velocity[1]), (0, 50), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0))\n",
    "        cv2.circle(debug, (int(hand.position[0]), int(hand.position[1])), 4, (255,0,0), -1)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ''' KEY POINTS/REGIONS '''\n",
    "    if hand_contour is not None:\n",
    "        most_left  = tuple(hand_contour[hand_contour[:, :, 0].argmin()][0])\n",
    "        most_right = tuple(hand_contour[hand_contour[:, :, 0].argmax()][0])\n",
    "        most_down  = tuple(hand_contour[hand_contour[:, :, 1].argmax()][0])\n",
    "\n",
    "        eoh = most_left if walks_left else most_right # end of hand\n",
    "        tl = (int(eoh[0]), int(hand.position[1]))\n",
    "        br = (int(hand.position[0]), h-1)\n",
    "        legs_roi = (tl, br) \n",
    "\n",
    "        # Debug\n",
    "        cv2.circle(debug, most_left, 4, (255,0,255), -1)\n",
    "        cv2.circle(debug, most_down, 4, (0,255,0), -1)\n",
    "        cv2.rectangle(debug, tl, br, (0,0,255), 2)\n",
    "\n",
    "    \n",
    "    \n",
    "    ''' EDGES '''\n",
    "#     edges = cv2.cvtColor(blurred, cv2.COLOR_BGR2GRAY)\n",
    "#     edges = cv2.adaptiveThreshold(edges, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "#     canny = cv2.Canny(blurred, 10, 10)\n",
    "    \n",
    "    \n",
    "        \n",
    "    ''' OPTICAL FLOW '''\n",
    "    next = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, **fb_params)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    \n",
    "    p0 = legs_roi[0]\n",
    "    p1 = legs_roi[1]\n",
    "    legs_mag = mag[p0[1]:p1[1], p0[0]:p1[0]]#*np.abs(np.cos(ang[p0[1]:p1[1], p0[0]:p1[0]]))\n",
    "    hand.leg_speed = np.mean(legs_mag)\n",
    "    \n",
    "    cv2.putText(debug, '{:.2f}'.format(np.mean(legs_mag)), (0, 30), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0))\n",
    "    \n",
    "    # Ignore non-hand movement\n",
    "    #mag = cv2.bitwise_and(mag, mag, mask=hand_mask)    \n",
    "       \n",
    "        \n",
    "        \n",
    "    ''' MHI '''\n",
    "#     mag_hist = mhi_alpha*mag_hist + (1-mhi_alpha)*mag\n",
    "#     ang_hist = mhi_alpha*ang_hist + (1-mhi_alpha)*ang\n",
    "#     mhi[...,0] = ang_hist*180/np.pi/2\n",
    "#     mhi[...,2] = cv2.normalize(mag_hist, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' GESTURES '''\n",
    "    hand.check_cooldowns()\n",
    "    cv2.putText(debug, hand.gestures_pretty() + hand.r_direction.value, (0, h), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0))\n",
    "    \n",
    "    ''' INPUT '''\n",
    "    if input_toggle:\n",
    "        if Gesture.JUMP in hand.gestures:\n",
    "            GameInput.jump()\n",
    "        else:\n",
    "            GameInput.stop_jump()\n",
    "\n",
    "        if Gesture.RUN in hand.gestures:\n",
    "            GameInput.walk(hand.r_direction)\n",
    "        else:\n",
    "            GameInput.stop_move()\n",
    "    \n",
    "    ''' OUTPUT/DEBUG '''\n",
    "    hand_mask = cv2.cvtColor(hand_mask, cv2.COLOR_GRAY2BGR)\n",
    "#     edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2BGR)\n",
    "#     canny = cv2.cvtColor(canny, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Create color representation of optical flow\n",
    "    flow_vis[...,0] = ang*180/np.pi/2\n",
    "    flow_vis[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    flow_vis_bgr = cv2.cvtColor(flow_vis,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Create color representation of mhi\n",
    "    mhi_bgr = cv2.cvtColor(mhi, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imshow('frame',np.hstack((debug, cv2.cvtColor(skin_mask, cv2.COLOR_GRAY2BGR), hand_mask, flow_vis_bgr))) #flow_vis_bgr, mhi_bgr)))\n",
    "\n",
    "    # Exit on ESC\n",
    "    key = cv2.waitKey(3) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "    if key == ord(' '):\n",
    "        input_toggle = not input_toggle\n",
    "    if key == ord('s'):\n",
    "        cv2.imwrite('{}.png'.format(str(time.time())), np.hstack((debug, cv2.cvtColor(skin_mask, cv2.COLOR_GRAY2BGR), hand_mask, flow_vis_bgr)))\n",
    "\n",
    "    prvs = next\n",
    "        \n",
    "kill_cap(cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case of emergency\n",
    "kill_cap(cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
