{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finger People experimental playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import urllib\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helpers import imshow\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Sources\n",
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cap(source, source_type='video'):\n",
    "    \n",
    "    if type(source) == int:\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        w = 180\n",
    "        h = w * 3/4\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, w) \n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, h) \n",
    "        #cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "        \n",
    "    elif source_type == 'video':\n",
    "        cap = cv2.VideoCapture(source)\n",
    "        cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "        \n",
    "    else:\n",
    "        cap = WebCapture(source)\n",
    "        \n",
    "    return cap\n",
    "\n",
    "def kill_cap(cap):\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_source = 'samples/all_moves_1_180.mp4'\n",
    "cap_type = 'video'\n",
    "\n",
    "# all_moves_1 sizes: 360, 180, 90, 46"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_source = 0\n",
    "cap_type = 'camera'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Android (via web)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap_source = 'http://192.168.1.4:8080/shot.jpg'\n",
    "cap_type = 'web'\n",
    "\n",
    "class WebCapture:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        \n",
    "    def read(self):\n",
    "        try:\n",
    "            img_resp = urllib.request.urlopen(self.url)\n",
    "            img_np = np.array(bytearray(img_resp.read()), dtype=np.uint8)\n",
    "            img = cv2.imdecode(img_np, -1)\n",
    "            return True, img\n",
    "        except:\n",
    "            return False, None\n",
    "        \n",
    "    def isOpened(self):\n",
    "        return True\n",
    "    \n",
    "    def release(self):\n",
    "        pass\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skin Detection Clibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hsv_mask(img, lower, upper):\n",
    "    '''\n",
    "    Given a BGR image, returns a mask of pixels within lower and upper HSV space\n",
    "    \n",
    "    mask = hsv_mask(img, lower, upper)\n",
    "    \n",
    "    input\n",
    "        img: A BGR image\n",
    "        lower: 3-tuple with hue, saturation, and value of lower cutoff of mask\n",
    "        upper: 3-tuple with hue, saturation, and value of upper cutoff of mask\n",
    "        \n",
    "    output\n",
    "        mask: binary mask of pixels with HSV values between lower and upper\n",
    "    '''\n",
    "    \n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    mask = np.zeros((img.shape[:2]), dtype=np.uint8)\n",
    "    \n",
    "    if lower[0] > upper[0]:\n",
    "        # To account for hue wrapping around 180 to 0\n",
    "        lower_middle = (180, upper[1], upper[2])\n",
    "        upper_middle = (0,   lower[1], lower[2])\n",
    "        \n",
    "        mask_lower = cv2.inRange(hsv, lower, lower_middle)\n",
    "        mask_upper = cv2.inRange(hsv, upper_middle, upper)\n",
    "        \n",
    "        mask = mask_lower + mask_upper\n",
    "        \n",
    "    else:\n",
    "        mask = cv2.inRange(hsv, lower, upper)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_roi_sample(cap, size=1/8):\n",
    "    '''\n",
    "    Draws a rectangle on the screen\n",
    "    Returns the pixels in the region upon pressing space\n",
    "    \n",
    "    size is a fraction of the screen height\n",
    "    '''\n",
    "    _ret, frame = cap.read()\n",
    "    h = frame.shape[0]\n",
    "    w = frame.shape[1]\n",
    "    \n",
    "    size /= 2\n",
    "    p0 = (int(w/2-h*size), int(h/2-h*size))\n",
    "    p1 = (int(w/2+h*size), int(h/2+h*size))\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        _ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)  \n",
    "        \n",
    "        #frame = cv2.GaussianBlur(frame, (13,13), 0)\n",
    "        \n",
    "        if not _ret:\n",
    "            break\n",
    "            \n",
    "        frame_display = frame.copy()\n",
    "        cv2.rectangle(frame_display, p0, p1, (0,255,0), 2)\n",
    "        cv2.imshow('frame', frame_display)\n",
    "        \n",
    "        key = cv2.waitKey(5)\n",
    "        if key == ord(' '):\n",
    "            break\n",
    "            \n",
    "    box_sample = frame[p0[1]:p1[1], p0[0]:p1[0]]\n",
    "    return box_sample\n",
    "\n",
    "def get_hsv_range(imgs):\n",
    "    '''\n",
    "    min_hsv, max_hsv = get_hsv_range(imgs)\n",
    "    \n",
    "    Finds and returns the bounds of a set of hsv images.\n",
    "    Shifts hue such that blue is around the 180/0 border \n",
    "    so that skin range can be easily evaluated\n",
    "    \n",
    "    Input\n",
    "        imgs: bgr images\n",
    "    \n",
    "    Output\n",
    "        min_hsv: 3-tuple containing the mininum hue, saturation, and value found in img\n",
    "        max_hsv: 3-tuple containing the maximum hue, saturation, and value found in img\n",
    "    '''\n",
    "    min_hsvs = []\n",
    "    max_hsvs = []\n",
    "    \n",
    "    for img in imgs:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        hue = img[:,:,0]\n",
    "        sat = img[:,:,1]\n",
    "        val = img[:,:,2]\n",
    "\n",
    "        hue = (hue + 90)%180 # shift skin hues away from the 180/0 border\n",
    "        min_hue, max_hue, _, _ = cv2.minMaxLoc(hue)\n",
    "        min_sat, max_sat, _, _ = cv2.minMaxLoc(sat)\n",
    "        min_val, max_val, _, _ = cv2.minMaxLoc(val)\n",
    "        \n",
    "        min_hsvs.append((min_hue, min_sat, min_val))\n",
    "        max_hsvs.append((max_hue, max_sat, max_val))\n",
    "        \n",
    "    # NOTE: these functions could be changed\n",
    "    #... using minimax for now\n",
    "    min_hsv = np.amin(np.array(min_hsvs), axis=0)\n",
    "    max_hsv = np.amax(np.array(max_hsvs), axis=0)\n",
    "    \n",
    "    min_hsv[0] = (min_hsv[0] + 90)%180\n",
    "    max_hsv[0] = (max_hsv[0] + 90)%180\n",
    "\n",
    "    return min_hsv, max_hsv\n",
    "\n",
    "def mean_hist(samples, channels=[0,1], ranges=[0,180,0,256], bins=[32,32]):\n",
    "    '''\n",
    "    Gets a mean histogram of all the sample images.\n",
    "    \n",
    "    Inputs:\n",
    "        samples is a list of sample images\n",
    "        channels defines the channels to use\n",
    "        ranges specifies the range of each channel\n",
    "        num_bins is the number of bins for each channel\n",
    "        \n",
    "    Outputs:\n",
    "        hist is the mean histogram\n",
    "    '''\n",
    "    hists = np.array([cv2.calcHist([sample], channels, None, bins, ranges) for sample in samples])\n",
    "    hist = np.mean(hists, axis=0)\n",
    "    return hist\n",
    "\n",
    "def hist_mask(img, hist, thresh=1, channels=[0,1], ranges=[0,180,0,256]):\n",
    "    backProj = cv2.calcBackProject([img], channels, hist, ranges, 1)\n",
    "    if thresh is not None:\n",
    "        ret, mask = cv2.threshold(backProj, 1, 255, cv2.THRESH_BINARY)\n",
    "    else:\n",
    "        mask = backProj\n",
    "    return mask\n",
    "\n",
    "\n",
    "# HSV ranges for skin detection (with perferct conditions)\n",
    "#skin_hsv_lower = np.array([0,  24,  80 ], dtype = \"uint8\")\n",
    "#skin_hsv_upper = np.array([20, 120, 255], dtype = \"uint8\")\n",
    "#skin_hsv_lower, skin_hsv_upper = get_hsv_range(skin_samples)  \n",
    "#print('Skin range {} {}'.format(skin_hsv_lower, skin_hsv_upper))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f39bb757ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HUE = 0\n",
    "SAT = 1\n",
    "channels = [HUE, SAT]\n",
    "\n",
    "HUE_RANGE = (0,180)\n",
    "SAT_RANGE = (0,256)\n",
    "ranges = [*HUE_RANGE, *SAT_RANGE]\n",
    "\n",
    "num_bins = 32\n",
    "bins = [num_bins]*len(channels)\n",
    "\n",
    "sat_thresh = 16 # any saturations below will be thrown out due to instability\n",
    "sat_thresh_bin = int(sat_thresh/SAT_RANGE[1]*num_bins)\n",
    "\n",
    "# Get samples of skin\n",
    "cap = get_cap(cap_source, cap_type)\n",
    "skin_samples = []\n",
    "for _ in range(5):\n",
    "    skin_samples.append(cv2.cvtColor(get_roi_sample(cap), cv2.COLOR_BGR2HSV))\n",
    "kill_cap(cap)\n",
    "\n",
    "# Calculate histogram\n",
    "skin_hist = mean_hist(skin_samples, channels=channels, ranges=ranges, bins=bins)\n",
    "skin_hist[:, :sat_thresh_bin] = 0\n",
    "plt.xlabel('Saturation')\n",
    "plt.ylabel('Hue')\n",
    "plt.imshow(skin_hist)\n",
    "\n",
    "# Create function to mask skin\n",
    "mask_skin = lambda frame, thresh=1: hist_mask(frame, skin_hist, thresh=thresh, channels=channels, ranges=ranges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finger People"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = get_cap(cap_source, cap_type)\n",
    "\n",
    "MIN_BLOB_SIZE = 50\n",
    "mhi_alpha = 0.5\n",
    "\n",
    "JUMP_THRESH = 1.0\n",
    "JUMP_RATIO  = 1.0 # x must be ratio more than y\n",
    "\n",
    "# Parameters for farneback optical flow\n",
    "fb_params = dict( pyr_scale = 0.5, \n",
    "                  levels = 3, \n",
    "                  winsize = 5, \n",
    "                  iterations = 3, \n",
    "                  poly_n = 5,\n",
    "                  poly_sigma = 1.2, \n",
    "                  flags = 0 )\n",
    "\n",
    "# Take the first frame\n",
    "_ret, init_frame = cap.read()\n",
    "prvs = cv2.cvtColor(init_frame,cv2.COLOR_BGR2GRAY)\n",
    "frame1 = cv2.flip(init_frame, 1)\n",
    "\n",
    "h = init_frame.shape[0]\n",
    "w = init_frame.shape[1]\n",
    "\n",
    "# For color representation of optical flow\n",
    "flow_vis = np.zeros_like(init_frame)\n",
    "flow_vis[...,1] = 255\n",
    "\n",
    "# Motion history image\n",
    "mag_hist = np.zeros((init_frame.shape[:2]), dtype=np.float32)\n",
    "ang_hist = np.zeros((init_frame.shape[:2]), dtype=np.float32)\n",
    "mhi = np.zeros_like(init_frame)\n",
    "mhi[...,1] = 255\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    # Get the next frame\n",
    "    _ret, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1)  \n",
    "    if not _ret:\n",
    "        break\n",
    "      \n",
    "    \n",
    "    \n",
    "    ''' SKIN MASK '''\n",
    "    #blurred = cv2.GaussianBlur(frame, (13,13), 0)\n",
    "    skin_mask = mask_skin(cv2.cvtColor(frame, cv2.COLOR_BGR2HSV), thresh=1)\n",
    "    hand_mask = skin_mask\n",
    "    #skin_mask = hsv_mask(cv2.GaussianBlur(frame, (13,13), 0), skin_hsv_lower, skin_hsv_upper)\n",
    "    \n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
    "#     skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_OPEN, kernel, iterations = 2)\n",
    "#     skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_CLOSE, kernel, iterations = 2)\n",
    "    \n",
    "#     # Find the lowest contour above the min size -- this should be a hand\n",
    "#     im, contours, hierarchy = cv2.findContours(skin_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "#     lowest_contour = None\n",
    "#     lowest_contour_height = math.inf\n",
    "    \n",
    "#     for i, contour in enumerate(contours):\n",
    "        \n",
    "#         if cv2.contourArea(contour) <= MIN_BLOB_SIZE:\n",
    "#             continue\n",
    "            \n",
    "#         m = cv2.moments(contour)\n",
    "#         contour_height = m['m10']/m['m00']\n",
    "\n",
    "#         if contour_height < lowest_contour_height:\n",
    "#             lowest_contour = i\n",
    "#             lowest_contour_height = contour_height\n",
    "            \n",
    "#     # Draw in hand blob\n",
    "#     hand_mask = np.zeros_like(skin_mask)\n",
    "#     if lowest_contour:\n",
    "#         cv2.drawContours(hand_mask, contours, lowest_contour, 255, -1)\n",
    "\n",
    "        \n",
    "        \n",
    "    ''' OPTICAL FLOW '''\n",
    "    next = cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs, next, None, **fb_params)\n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    \n",
    "    # Ignore non-hand movement\n",
    "    #mag = cv2.bitwise_and(mag, mag, mask=hand_mask)    \n",
    "       \n",
    "        \n",
    "        \n",
    "    ''' MHI '''\n",
    "    mag_hist = mhi_alpha*mag_hist + (1-mhi_alpha)*mag\n",
    "    ang_hist = mhi_alpha*ang_hist + (1-mhi_alpha)*ang\n",
    "    mhi[...,0] = ang_hist*180/np.pi/2\n",
    "    mhi[...,2] = cv2.normalize(mag_hist, None, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    y_hist, x_hist = cv2.polarToCart(mag_hist, ang_hist)\n",
    "    mhi_avg_x = -1*np.mean(x_hist)\n",
    "    mhi_avg_y = np.mean(y_hist)\n",
    "    \n",
    "    # debug\n",
    "    cv2.arrowedLine(frame, (int(w/2), int(h/2)), (int(w/2+-20*mhi_avg_y), int(h/2+-20*mhi_avg_x)), (0,0,255), 2)\n",
    "    cv2.putText(frame, '{},{}'.format(int(mhi_avg_x*30), int(mhi_avg_y*30)), (0, 50), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' GESTURES '''\n",
    "    gesture = 'idle'\n",
    "    if mhi_avg_x > JUMP_THRESH and abs(mhi_avg_x) > abs(mhi_avg_y)*JUMP_RATIO:\n",
    "        gesture = 'jump up'\n",
    "    if mhi_avg_x < -1*JUMP_THRESH and abs(mhi_avg_x) > abs(mhi_avg_y)*JUMP_RATIO:\n",
    "        gesture = 'jump down'\n",
    "        \n",
    "    cv2.putText(frame, gesture, (0, h), cv2.FONT_HERSHEY_DUPLEX, 0.5, (0,255,0))\n",
    "    \n",
    "    \n",
    "    \n",
    "    ''' OUTPUT/DEBUG '''\n",
    "    hand_mask = cv2.cvtColor(hand_mask, cv2.COLOR_GRAY2BGR)\n",
    "    \n",
    "    # Create color representation of optical flow\n",
    "    flow_vis[...,0] = ang*180/np.pi/2\n",
    "    flow_vis[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "    flow_vis_bgr = cv2.cvtColor(flow_vis,cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    # Create color representation of mhi\n",
    "    mhi_bgr = cv2.cvtColor(mhi, cv2.COLOR_HSV2BGR)\n",
    "    \n",
    "    cv2.imshow('frame',np.hstack((frame, cv2.cvtColor(skin_mask, cv2.COLOR_GRAY2BGR), hand_mask, flow_vis_bgr, mhi_bgr)))\n",
    "\n",
    "    # Exit on ESC\n",
    "    key = cv2.waitKey(30) & 0xFF\n",
    "    if key == 27:\n",
    "        break\n",
    "    if key == ord('q'):\n",
    "        break\n",
    "\n",
    "    prvs = next\n",
    "        \n",
    "kill_cap(cap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
